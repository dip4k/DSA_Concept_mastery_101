# Week 2, Day 3: Linked Lists

## ğŸ—“ Metadata
**Week:** 2 | **Day:** 3 of 5 | **Topic:** Linked Lists  
**Category:** Linear Structures | **Difficulty:** ğŸŸ¡ Medium  
**Prerequisites:** Week 1 (Pointers), Week 2 Day 1-2 (Arrays)  
**Time:** 90-120 minutes

---

## 1ï¸âƒ£ THE WHY â€” Engineering Motivation

**Real-World Problem:**
You're implementing browser history. Users can add, remove, and navigate through history. Inserting in the middle of an array is O(n). Allocating huge capacity for unknown size wastes memory.

**Design Problems Solved:**
- O(1) insertion/deletion at known position (given pointer)
- No need to preallocate size
- Support for efficient undo/redo (doubly-linked)
- Foundation for many data structures (hash table chaining, graph adjacency lists)

**Real System Usage:**
- **Memory allocators (malloc):** Linked lists of free blocks
- **Operating System:** Process queues, run queues
- **LRU Cache:** Doubly-linked list + hash map
- **Graph representation:** Adjacency lists

---

## 2ï¸âƒ£ THE WHAT â€” Mental Model & Intuition

**Core Analogy:**
Think of a linked list like a treasure hunt:

```
You have a treasure map with clues:
Clue 1: "X marks the spot. Next clue is at address 0x7000"
Clue 2: "Dig here. Next clue is at address 0x8000"
Clue 3: "Gold found! No more clues (next = NULL)"

To find treasure:
- Start at clue 1 (head pointer)
- Read clue 1, follow pointer to clue 2
- Read clue 2, follow pointer to clue 3
- Read clue 3, treasure!
```

Memory layout (scattered, NOT contiguous):
```
Address 0x5000 (head): Node 1 â†’ [value: 10, next: 0x7000]
Address 0x7000:        Node 2 â†’ [value: 20, next: 0x8000]
Address 0x8000:        Node 3 â†’ [value: 30, next: NULL]
```

---

## 3ï¸âƒ£ THE HOW â€” Mechanical Walkthrough

**State:**
```
struct Node {
    int value;
    Node* next;
};

LinkedList {
    Node* head;     // pointer to first node
    int size;       // number of nodes
}
```

**Access node at position i:**
1. Start at head
2. Follow next pointer i times
3. Return node

**Cost:** O(i) â€” must traverse from beginning

**Insert at known position (given node_ptr):**
1. Create new node with value
2. new_nodeâ†’next = node_ptrâ†’next
3. node_ptrâ†’next = new_node
4. Increment size

**Cost:** O(1) â€” just relink pointers

**Delete at known position:**
1. Get reference to previous node (prev_ptr)
2. prev_ptrâ†’next = node_ptrâ†’next
3. Free node_ptr

**Cost:** O(1) â€” just relink

---

## 4ï¸âƒ£ VISUALIZATION â€” Simulation & Examples

**Example 1: Access element at position 2**

```
Original: [10] â†’ [20] â†’ [30] â†’ [40] â†’ NULL

Step 1: Start at head â†’ 10
Step 2: Follow next â†’ 20
Step 3: Follow next â†’ 30 (reached position 2)

Result: 30

Cost: 3 pointer dereferences = O(3) = O(n) general
```

**Example 2: Insert 25 after position 1**

```
Before:  head: [10] â†’ [20] â†’ [30] â†’ NULL
              
Want: [10] â†’ [25] â†’ [20] â†’ [30] â†’ NULL

Insert after node containing 10:
1. Create new node: [25, ???]
2. new_nodeâ†’next = 10_nodeâ†’next = pointer to [20]
3. 10_nodeâ†’next = pointer to [25]
4. Result: [10] â†’ [25] â†’ [20] â†’ [30] â†’ NULL

Operations: 3 pointer assignments = O(1)
```

**Example 3: Delete position 1**

```
Before:  [10] â†’ [20] â†’ [30] â†’ NULL

Delete node with 20:
1. Find previous node (10)
2. 10_nodeâ†’next = 20_nodeâ†’next = pointer to [30]
3. Free [20]
4. Result: [10] â†’ [30] â†’ NULL

Operations: 2 pointer assignments = O(1)
```

---

## 5ï¸âƒ£ CRITICAL ANALYSIS â€” Performance & Robustness

| Operation | Best | Average | Worst | Notes |
|-----------|------|---------|-------|-------|
| **Access position i** | O(1) at head | O(n/2) average | O(n) at tail | Must traverse |
| **Insert at head** | O(1) | O(1) | O(1) | Don't need to traverse |
| **Insert at position i** | O(1)* | O(1)* | O(1)* | *If you have pointer to node |
| **Insert at tail** | O(n) | O(n) | O(n) | Must traverse to find end |
| **Delete at head** | O(1) | O(1) | O(1) | Just relink |
| **Delete at position i** | O(1)* | O(1)* | O(1)* | *If you have pointer |
| **Space** | O(n) | O(n) | O(n) | Extra space for pointers |

**Cache Behavior:**
- Linked lists: Each node pointer dereference = cache miss (scattered memory)
- Typical: ~5% cache hit (1 out of 20 accesses hits cache)
- Sequential list traversal: 20-50x slower than array traversal

```
Array traversal (sequential):
  for (int i = 0; i < n; i++)
    sum += arr[i];      // All nearby, cache hits 95%+
  Time: O(n) with small constant

List traversal (scattered pointers):
  for (Node* p = head; p; p = pâ†’next)
    sum += pâ†’value;     // Pointers scattered, cache misses 95%+
  Time: O(n) with 50x larger constant!
```

---

## 6ï¸âƒ£ REAL SYSTEM INTEGRATION

**Linux Memory Allocator (jemalloc):**
- Free blocks stored in linked lists
- Quick insertion/removal
- Coalescing: O(1) if adjacent free blocks linked

**LRU Cache:**
```
struct LRU {
    Node* head, tail;         // doubly-linked list (insertion/deletion O(1))
    HashMap<key, Node*> map;  // quick lookup
};
```
Evicting least-recently-used = removal from tail in O(1)

**Process Scheduler:**
- OS maintains process queue as linked list
- Add process at tail: O(1)
- Remove when done: O(1)

---

## 7ï¸âƒ£ CONCEPT CROSSOVERS

**Builds on:** Pointers, arrays  
**Built by:** Hash tables (chaining), graphs (adjacency lists), deques

---

## 8ï¸âƒ£ MATHEMATICAL & THEORETICAL PERSPECTIVE

**Key Property:** Pointer-based access prevents O(1) indexing.

**Proof:**
- To access position i, must follow i pointers
- Each pointer dereference: one memory load
- Total: i loads = O(i)

**vs Arrays:**
- Address = base + i Ã— size (arithmetic, no loads needed!)
- Total: 1 load = O(1)

---

## 9ï¸âƒ£ ALGORITHMIC DESIGN INTUITION

**When to use:**
- Frequent O(1) insertion/deletion at known positions
- Undo/redo (doubly-linked)
- Memory allocator free list
- **Rarely for other reasons!**

**When NOT to use:**
- Need random access (array better)
- Cache matters (array better)
- Memory overhead acceptable (array takes less space per element)

---

## ğŸ”Ÿ KNOWLEDGE CHECK â€” Socratic Reasoning

**Q1:** Inserting at position i in a linked list is O(1) if you have a pointer to position i-1. But how long to *find* that position initially?

**Q2:** A doubly-linked list stores prev and next pointers. What's the benefit over singly-linked? Cost?

**Q3:** Why does the C memory allocator use linked lists for free blocks but arrays for allocated blocks?

**Q4:** Cache miss latency is 200ns, array access 5ns, list access 200ns. For n=1000, which is faster: array or list scan?

---

## 1ï¸âƒ£1ï¸âƒ£ RETENTION HOOK â€” Memory Anchors

**One-Liner:**
> **Linked lists: O(1) insert/delete at known position via pointer relink; O(n) access via traversal; 50x slower than arrays due to cache.**

**Mnemonic:** "P.O.P." â€” Pointers, One per node, Pointers scatter

---

## Supplementary: Practice

1. Implement singly-linked list with insert/delete
2. Implement doubly-linked list for deque
3. Merge two sorted linked lists in O(n) time

